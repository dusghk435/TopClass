{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d0cf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeonhwa\\Desktop\\Mask_RCNN\\mrcnn\\model.py:2315: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if os.name is 'nt':\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_balloon.h5\")\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "DEFAULT_DATASET_YEAR = \"2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1fcf0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Configurations\n",
    "###################\n",
    "\n",
    "class FashionConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"fashion\"\n",
    "    \n",
    "    IMAGES_PER_GPU = 2\n",
    "    \n",
    "    NUM_CLASSES = 1 + 21 #\n",
    "    \n",
    "    STEPS_PER_EPOCH = 100\n",
    "    \n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cadd32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f3cb0cbc1b4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# BalloonDataset -> TshirtDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mFashionDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_fashion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \"\"\"Generate instance masks for an image.\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "\n",
    "# BalloonDataset -> TshirtDataset\n",
    "class FashionDataset(utils.Dataset):\n",
    "    def load_fashion(self, dataset_dir, subset, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        \n",
    "        class_list = [\"top\", \"blouse\", \"tshirts\", \"knitwear\", \"shirts\", \"bratop\", \"hoodie\",\n",
    "                      \"jean\",\"pants\",\"skirt\",\"leggings\",\"joggerPants\", \n",
    "                      \"coat\", \"jacket\", \"jumper\", \"padding\", \"vest\", \"cardigon\", \"zipUp\",\n",
    "                      \"dress\", \"jumpsuite\"]\n",
    "        \n",
    "        #Add classes\n",
    "        num=1\n",
    "        for i in class_list:\n",
    "            self.add_class(\"fashion\",num,i)\n",
    "            num=num+1\n",
    "            \n",
    "        #Add images\n",
    "        #나중에에에에에ㅔ에에에에ㅔ에에에에에\n",
    "        \n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        # polygon을 비트맵 마스크로 바꾸는 부분\n",
    "        # 마스크 shape는 [height, width, instance_count]\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "    \n",
    "\n",
    "    #나중에ㅔ에에에에에에에ㅔ\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"fashion\":\n",
    "            return info[\"fashion\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1283c3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ceff6a7eeebb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#Configuration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFashionConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "#  Training\n",
    "############################################################\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    #Parse command line arguments\n",
    "    \n",
    "    #Configuration\n",
    "    if args.command == \"train\":\n",
    "        config = FashionConfig()\n",
    "    else:\n",
    "        class InferenceConfig(FashionConfig):\n",
    "            # Set batch size to 1 since we'll be running inference on\n",
    "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = 1\n",
    "        config = InferenceConfig()\n",
    "    config.display()\n",
    "\n",
    "    #Create model\n",
    "    if args.command == \"train\":\n",
    "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "    else:\n",
    "        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "        \n",
    "    #Load weights\n",
    "    \"\"\"Modified version of the corresponding Keras function with\n",
    "    the addition of multi-GPU support and the ability to exclude\n",
    "    some layers from loading.\n",
    "    exclude: list of layer names to exclude\n",
    "    \"\"\"\n",
    "    if args.weights.lower() == \"path\":\n",
    "        model.load_weights(FASHION_MODEL_PATH, by_name=True)\n",
    "    else:\n",
    "        model.load_weights(model.find_last(), by_name=True)\n",
    "    \n",
    "    #Train or evaluate\n",
    "    def train(self, train_dataset, val_dataset, learning_rate, epochs, layers,\n",
    "              augmentation=None, custom_callbacks=None, no_augmentation_sources=None):\n",
    "        \"\"\"Train the model.\n",
    "        train_dataset, val_dataset: Training and validation Dataset objects.\n",
    "        learning_rate: The learning rate to train with\n",
    "        epochs: Number of training epochs. Note that previous training epochs\n",
    "                are considered to be done alreay, so this actually determines\n",
    "                the epochs to train in total rather than in this particaular\n",
    "                call.\n",
    "        layers: Allows selecting wich layers to train. It can be:\n",
    "            - A regular expression to match layer names to train\n",
    "            - One of these predefined values:\n",
    "              heads: The RPN, classifier and mask heads of the network\n",
    "              all: All the layers\n",
    "              3+: Train Resnet stage 3 and up\n",
    "              4+: Train Resnet stage 4 and up\n",
    "              5+: Train Resnet stage 5 and up\n",
    "        augmentation: Optional. An imgaug (https://github.com/aleju/imgaug)\n",
    "            augmentation. For example, passing imgaug.augmenters.Fliplr(0.5)\n",
    "            flips images right/left 50% of the time. You can pass complex\n",
    "            augmentations as well. This augmentation applies 50% of the\n",
    "            time, and when it does it flips images right/left half the time\n",
    "            and adds a Gaussian blur with a random sigma in range 0 to 5.\n",
    "                augmentation = imgaug.augmenters.Sometimes(0.5, [\n",
    "                    imgaug.augmenters.Fliplr(0.5),\n",
    "                    imgaug.augmenters.GaussianBlur(sigma=(0.0, 5.0))\n",
    "                ])\n",
    "\t    custom_callbacks: Optional. Add custom callbacks to be called\n",
    "\t        with the keras fit_generator method. Must be list of type keras.callbacks.\n",
    "        no_augmentation_sources: Optional. List of sources to exclude for\n",
    "            augmentation. A source is string that identifies a dataset and is\n",
    "            defined in the Dataset class.\n",
    "        \"\"\"\n",
    "    if args.command == \"train\":\n",
    "        train()\n",
    "    else:\n",
    "        detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7834a2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
